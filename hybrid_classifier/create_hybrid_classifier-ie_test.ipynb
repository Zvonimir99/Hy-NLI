{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the hybrid classifier\n",
    "(the script is written for hybridizing with BERT. Just replace 'BERT' with 'XLNet' to get hybridization with XLNet.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Producing the training (or testing) set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn import metrics \n",
    "from sklearn.utils import resample\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/adam/anaconda3/envs/tensorflow/lib/python3.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.23.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n  UserWarning)\n/home/adam/anaconda3/envs/tensorflow/lib/python3.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.23.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# import the trained model\n",
    "import pickle\n",
    "filename = 'mlp_model_trained_on_bert.sav'\n",
    "trained_model = pickle.load(open(filename, 'rb'))\n",
    "mlp = trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "C\n",
      "C\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "C\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "C\n",
      "E\n",
      "N\n",
      "C\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "C\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "C\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "C\n",
      "N\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "C\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "C\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "C\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "C\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "C\n",
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "C\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "C\n",
      "E\n",
      "C\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "C\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "C\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "C\n",
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "C\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "C\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "C\n",
      "E\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "C\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "C\n",
      "C\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "C\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "0 0 0.825485336637753\n",
      "C\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "C\n",
      "E\n",
      "C\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "C\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "N\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n",
      "E\n",
      "C\n",
      "N\n",
      "N\n",
      "N\n",
      "C\n",
      "N\n",
      "N\n",
      "C\n",
      "E\n",
      "E\n",
      "N\n",
      "N\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-18e181a1fbbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mtest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray2string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0mtest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"]\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m#print (test_id)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mvalues\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5671\u001b[0m         \"\"\"\n\u001b[1;32m   5672\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_REVERSED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5675\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mas_array\u001b[0;34m(self, transpose, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m    870\u001b[0m                     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;31m# The underlying data was copied within _interleave\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m    909\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[0mitemmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mget_values\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \"\"\"\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bert_path_base = '/home/adam/anu/comp4450/hy-nli/Hy-NLI/output/bert/results/untransform/results-untransform-rho'\n",
    "gkr_path = '/home/adam/anu/comp4450/hy-nli/Hy-NLI/gkr4nli/data/untransformed/sick_test_untransform-results.csv' \n",
    "merged_file_base = '/home/adam/anu/comp4450/hy-nli/Hy-NLI/output/hybrid/sick_input/untransform-rho'\n",
    "output_path_base = '/home/adam/anu/comp4450/hy-nli/Hy-NLI/output/hybrid/untransform/results-hy-nli-untransform-rho'\n",
    "\n",
    "for rho in range(0,120,20):\n",
    "    r = str(rho)\n",
    "    for experiment in range(5):\n",
    "        e = str(experiment)\n",
    "        end = r + '-' + e + '.csv'\n",
    "        bert_path = bert_path_base + end\n",
    "        merged_file = merged_file_base + end\n",
    "        output_path = output_path_base + end\n",
    "\n",
    "        \n",
    "        # first\n",
    "        dlFile = open (bert_path, 'r')\n",
    "        symbFile = open (gkr_path, 'r')\n",
    "        mergedFile = open (merged_file, 'w')\n",
    "        mergedFile.write(\"ID\\tComplexCtxs\\tContraFlag\\tVeridical\\tAntiveridical\\tAveridical\\tEquals\\tSuperclass\\tSubclass\\tDisjoint\\tTargetLabel\\n\")\n",
    "\n",
    "        # second\n",
    "        # Read the files and initialize parameters\n",
    "        dlLines = dlFile.readlines()\n",
    "        symbLines = symbFile.readlines()\n",
    "        # Create a dictionary holding the predicted label of the DL model. Will need it for evaluation as well.\n",
    "        dict_of_dl_labels = defaultdict()\n",
    "\n",
    "        # third\n",
    "        for line in dlLines:\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            elements = line.split(\"\\t\")\n",
    "            dict_of_dl_labels[elements[0]] = elements[1].replace(\"0\", \"E\").replace(\"1\", \"C\").replace(\"2\", \"N\")\n",
    "\n",
    "\n",
    "        # fourth\n",
    "        for line in symbLines:\n",
    "            if line.startswith(\"pair_ID\"):\n",
    "                continue\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            elements = line.split(\"\\t\")\n",
    "            elements = elements[0:-1]\n",
    "            id_ = elements[0]\n",
    "            gold_label = elements[1]\n",
    "            features = elements[2:-1]\n",
    "            symb_label = elements[-1]\n",
    "            dl_label = dict_of_dl_labels[id_]\n",
    "            target_label = \"\"\n",
    "            if dl_label == gold_label and symb_label == gold_label:\n",
    "                target_label = \"B\"\n",
    "            elif dl_label == gold_label:\n",
    "                target_label = \"DL\"\n",
    "            elif symb_label == gold_label:\n",
    "                target_label = \"S\"\n",
    "            else:\n",
    "                target_label = \"N\"\n",
    "            mergedFile.write(id_+\"\\t\"+\"\\t\".join([str(f) for f in features])+\"\\t\" + target_label+\"\\n\")\n",
    "\n",
    "\n",
    "        # Close all opened files.\n",
    "        dlFile.close()\n",
    "        symbFile.close()\n",
    "        mergedFile.close()\n",
    "\n",
    "\n",
    "\n",
    "        # evaluate\n",
    "        dlFile_TEST = open(bert_path, \"r\")\n",
    "        symbFile_TEST = open(gkr_path, \"r\")\n",
    "\n",
    "        # Read the files\n",
    "        dlLines_TEST = dlFile_TEST.readlines()\n",
    "        symbLines_TEST = symbFile_TEST.readlines()\n",
    "\n",
    "        # Create a dictionary holding the predicted label of the DL model.\n",
    "        dict_of_dl_labels_TEST = defaultdict()\n",
    "        # Create a dictionary holding the predicted label of the GKR4NLI.\n",
    "        dict_of_symb_labels_TEST = defaultdict()\n",
    "        # Create a dictionary holding the gold label.\n",
    "        dict_of_gold_labels_TEST = defaultdict()\n",
    "\n",
    "\n",
    "        # Go through the dl file and store the predicted label of each pair in a dictionary.\n",
    "        for line in dlLines_TEST:\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            elements = line.split(\"\\t\")\n",
    "            dict_of_dl_labels_TEST[elements[0]] = elements[1].replace(\"0\", \"E\").replace(\"1\", \"C\").replace(\"2\", \"N\")\n",
    "\n",
    "            \n",
    "        # Go through the symbolic file and store the predicted label of GKR4NLI and the gold labels of each pair in a dictionary.\n",
    "        for line in symbLines_TEST:\n",
    "            if line.startswith(\"pair_ID\"):\n",
    "                continue\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            elements = line.split(\"\\t\")\n",
    "            elements = elements[0:-1]\n",
    "            id_ = elements[0]\n",
    "            gold_label = elements[1]\n",
    "            dict_of_gold_labels_TEST[id_] = gold_label\n",
    "            symb_label = elements[-1]\n",
    "            dict_of_symb_labels_TEST[id_] = symb_label\n",
    "\n",
    "\n",
    "        # six\n",
    "        # Read test set to evaluate on it.\n",
    "        test_data = pd.read_csv(merged_file, sep='\\t', header=0)\n",
    "\n",
    "        # print (\"Dataset Lenght:: \", len(test_data))\n",
    "        # print (\"Dataset Shape:: \", test_data.shape)\n",
    "\n",
    "        # print (\"Dataset:: \")\n",
    "        # print (test_data.head())\n",
    "\n",
    "\n",
    "        X_test = test_data.values[:, 1:-1]\n",
    "        Y_test = test_data.values[:, -1]\n",
    "\n",
    "\n",
    "        # seven\n",
    "        # Predict labels for test set. The predicted labels are one of S, DL or B, expressing the component that the hybrid \n",
    "        # classifier predicted to get the inference relation right.\n",
    "        predicted = mlp.predict(X_test)\n",
    "        # Write the final results into a file for better error-analysis.\n",
    "        outputFile = open(output_path, 'w')\n",
    "        outputFile.write(\"pair_ID\\tHybridLabel\\tMappedLabel\\tGoldLabel\\n\")\n",
    "\n",
    "        i = 0\n",
    "        correct = 0\n",
    "        for pred in predicted:\n",
    "            test_id = np.array2string(test_data.values[i:i+1,0])\n",
    "            test_id = test_id.replace(\"'\",\"\").replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "            #print (test_id)\n",
    "            i += 1\n",
    "            dl_pred = dict_of_dl_labels_TEST[test_id]\n",
    "            symb_pred = dict_of_symb_labels_TEST[test_id]\n",
    "            # print(symb_pred)\n",
    "            gold = dict_of_gold_labels_TEST[test_id]\n",
    "            hybrid_pred = \"\"   \n",
    "            # map hybrid prediction to a proper inference label\n",
    "            # if you are using our trained classifier, you have to use the following code: (because we used slighlty different\n",
    "            # abbreviations for each label -- B for BERT, R for rule-based and BR for bert/rule-based) \n",
    "            if pred == \"B\":\n",
    "                hybrid_pred = dl_pred\n",
    "            elif pred == \"R\":\n",
    "                hybrid_pred = symb_pred\n",
    "            elif pred == \"BR\":\n",
    "                hybrid_pred = dl_pred\n",
    "            # If you have trained your own model, please use following code (and abbreviations):\n",
    "            # if pred == \"DL\":\n",
    "            #    hybrid_pred = dl_pred\n",
    "            # if pred == \"DL\":\n",
    "            #    hybrid_pred = dl_pred\n",
    "            # elif pred == \"S\":\n",
    "            #    hybrid_pred = symb_pred\n",
    "            # elif pred == \"B\":\n",
    "            #    hybrid_pred = dl_pred        \n",
    "            # Check how many hybrid labels are indeed the correct labels.\n",
    "            #print (hybrid_pred+ \" \"+gold)\n",
    "            outputFile.write(test_id+\"\\t\"+pred+\"\\t\"+hybrid_pred+\"\\t\"+gold+\"\\n\")\n",
    "            # !!!!!!! if you are evaluating on HANS, you need the following line to merge C and N to N !!!!!!!!\n",
    "            #hybrid_pred = hybrid_pred.replace(\"C\", \"N\")\n",
    "            if hybrid_pred == gold:\n",
    "                correct += 1\n",
    "            \n",
    "        # print (\"No of correct classifications: \"+str(correct))\n",
    "        # print (\"Percentage of correct classifications: \"+str(correct/(len(test_data))))\n",
    "        print(r, e, correct/len(test_data))\n",
    "\n",
    "        # dlFile_TEST.close()\n",
    "        # symbLines_TEST.close()\n",
    "        outputFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 0 0.6638359569179785\n",
      "0 1 0.6628003314001657\n",
      "0 2 0.6269676884838442\n",
      "0 3 0.6648715824357913\n",
      "0 4 0.6783347141673571\n",
      "20 0 0.6806130903065452\n",
      "20 1 0.6853769676884839\n",
      "20 2 0.6901408450704225\n",
      "20 3 0.6849627174813587\n",
      "20 4 0.6673570836785419\n",
      "40 0 0.6810273405136703\n",
      "40 1 0.6812344656172328\n",
      "40 2 0.6795774647887324\n",
      "40 3 0.6895194697597349\n",
      "40 4 0.679784589892295\n",
      "60 0 0.68019884009942\n",
      "60 1 0.6868268434134217\n",
      "60 2 0.682062966031483\n",
      "60 3 0.6864125932062966\n",
      "60 4 0.6870339685169843\n",
      "80 0 0.6804059652029826\n",
      "80 1 0.6870339685169843\n",
      "80 2 0.6845484672742337\n",
      "80 3 0.6915907207953604\n",
      "80 4 0.6924192212096106\n",
      "100 0 0.6866197183098591\n",
      "100 1 0.6816487158243579\n",
      "100 2 0.6783347141673571\n",
      "100 3 0.6878624689312345\n",
      "100 4 0.6833057166528583\n"
     ]
    }
   ],
   "source": [
    "bert_path_base = '/home/adam/anu/comp4450/hy-nli/Hy-NLI/output/bert/results/transform/results-transform-rho'\n",
    "gkr_path = '/home/adam/anu/comp4450/hy-nli/Hy-NLI/gkr4nli/data/transformed/sick_test_transform-results.csv' \n",
    "merged_file_base = '/home/adam/anu/comp4450/hy-nli/Hy-NLI/output/hybrid/sick_input/transform-rho'\n",
    "output_path_base = '/home/adam/anu/comp4450/hy-nli/Hy-NLI/output/hybrid/transform/results-hy-nli-transform-rho'\n",
    "\n",
    "for rho in range(0,120,20):\n",
    "    r = str(rho)\n",
    "    for experiment in range(5):\n",
    "        e = str(experiment)\n",
    "        end = r + '-' + e + '.csv'\n",
    "        bert_path = bert_path_base + end\n",
    "        merged_file = merged_file_base + end\n",
    "        output_path = output_path_base + end\n",
    "\n",
    "        \n",
    "        # first\n",
    "        dlFile = open (bert_path, 'r')\n",
    "        symbFile = open (gkr_path, 'r')\n",
    "        mergedFile = open (merged_file, 'w')\n",
    "        mergedFile.write(\"ID\\tComplexCtxs\\tContraFlag\\tVeridical\\tAntiveridical\\tAveridical\\tEquals\\tSuperclass\\tSubclass\\tDisjoint\\tTargetLabel\\n\")\n",
    "\n",
    "        # second\n",
    "        # Read the files and initialize parameters\n",
    "        dlLines = dlFile.readlines()\n",
    "        symbLines = symbFile.readlines()\n",
    "        # Create a dictionary holding the predicted label of the DL model. Will need it for evaluation as well.\n",
    "        dict_of_dl_labels = defaultdict()\n",
    "\n",
    "        # third\n",
    "        for line in dlLines:\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            elements = line.split(\"\\t\")\n",
    "            dict_of_dl_labels[elements[0]] = elements[1].replace(\"0\", \"E\").replace(\"1\", \"C\").replace(\"2\", \"N\")\n",
    "\n",
    "\n",
    "        # fourth\n",
    "        for line in symbLines:\n",
    "            if line.startswith(\"pair_ID\"):\n",
    "                continue\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            elements = line.split(\"\\t\")\n",
    "            elements = elements[0:-1]\n",
    "            id_ = elements[0]\n",
    "            gold_label = elements[1]\n",
    "            features = elements[2:-1]\n",
    "            symb_label = elements[-1]\n",
    "            if id_ not in dict_of_dl_labels.keys():\n",
    "                continue\n",
    "            dl_label = dict_of_dl_labels[id_]\n",
    "            target_label = \"\"\n",
    "            if dl_label == gold_label and symb_label == gold_label:\n",
    "                target_label = \"B\"\n",
    "            elif dl_label == gold_label:\n",
    "                target_label = \"DL\"\n",
    "            elif symb_label == gold_label:\n",
    "                target_label = \"S\"\n",
    "            else:\n",
    "                target_label = \"N\"\n",
    "            mergedFile.write(id_+\"\\t\"+\"\\t\".join([str(f) for f in features])+\"\\t\" + target_label+\"\\n\")\n",
    "\n",
    "\n",
    "        # Close all opened files.\n",
    "        dlFile.close()\n",
    "        symbFile.close()\n",
    "        mergedFile.close()\n",
    "\n",
    "\n",
    "\n",
    "        # evaluate\n",
    "        dlFile_TEST = open(bert_path, \"r\")\n",
    "        symbFile_TEST = open(gkr_path, \"r\")\n",
    "\n",
    "        # Read the files\n",
    "        dlLines_TEST = dlFile_TEST.readlines()\n",
    "        symbLines_TEST = symbFile_TEST.readlines()\n",
    "\n",
    "        # Create a dictionary holding the predicted label of the DL model.\n",
    "        dict_of_dl_labels_TEST = defaultdict()\n",
    "        # Create a dictionary holding the predicted label of the GKR4NLI.\n",
    "        dict_of_symb_labels_TEST = defaultdict()\n",
    "        # Create a dictionary holding the gold label.\n",
    "        dict_of_gold_labels_TEST = defaultdict()\n",
    "\n",
    "\n",
    "        # Go through the dl file and store the predicted label of each pair in a dictionary.\n",
    "        for line in dlLines_TEST:\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            elements = line.split(\"\\t\")\n",
    "            dict_of_dl_labels_TEST[elements[0]] = elements[1].replace(\"0\", \"E\").replace(\"1\", \"C\").replace(\"2\", \"N\")\n",
    "\n",
    "            \n",
    "        # Go through the symbolic file and store the predicted label of GKR4NLI and the gold labels of each pair in a dictionary.\n",
    "        for line in symbLines_TEST:\n",
    "            if line.startswith(\"pair_ID\"):\n",
    "                continue\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            elements = line.split(\"\\t\")\n",
    "            id_ = elements[0]\n",
    "            gold_label = elements[1]\n",
    "            dict_of_gold_labels_TEST[id_] = gold_label\n",
    "            symb_label = elements[-1]\n",
    "            dict_of_symb_labels_TEST[id_] = symb_label\n",
    "\n",
    "\n",
    "        # six\n",
    "        # Read test set to evaluate on it.\n",
    "        test_data = pd.read_csv(merged_file, sep='\\t', header=0)\n",
    "\n",
    "        # print (\"Dataset Lenght:: \", len(test_data))\n",
    "        # print (\"Dataset Shape:: \", test_data.shape)\n",
    "\n",
    "        # print (\"Dataset:: \")\n",
    "        # print (test_data.head())\n",
    "\n",
    "\n",
    "        X_test = test_data.values[:, 1:-1]\n",
    "        Y_test = test_data.values[:, -1]\n",
    "\n",
    "\n",
    "        # seven\n",
    "        # Predict labels for test set. The predicted labels are one of S, DL or B, expressing the component that the hybrid \n",
    "        # classifier predicted to get the inference relation right.\n",
    "        predicted = mlp.predict(X_test)\n",
    "        # Write the final results into a file for better error-analysis.\n",
    "        outputFile = open(output_path, 'w')\n",
    "        outputFile.write(\"pair_ID\\tHybridLabel\\tMappedLabel\\tGoldLabel\\n\")\n",
    "\n",
    "        i = 0\n",
    "        correct = 0\n",
    "        for pred in predicted:\n",
    "            test_id = np.array2string(test_data.values[i:i+1,0])\n",
    "            test_id = test_id.replace(\"'\",\"\").replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "            #print (test_id)\n",
    "            i += 1\n",
    "            dl_pred = dict_of_dl_labels_TEST[test_id]\n",
    "            symb_pred = dict_of_symb_labels_TEST[test_id]\n",
    "            gold = dict_of_gold_labels_TEST[test_id]\n",
    "            hybrid_pred = \"\"   \n",
    "            # map hybrid prediction to a proper inference label\n",
    "            # if you are using our trained classifier, you have to use the following code: (because we used slighlty different\n",
    "            # abbreviations for each label -- B for BERT, R for rule-based and BR for bert/rule-based) \n",
    "            if pred == \"B\":\n",
    "                hybrid_pred = dl_pred\n",
    "            elif pred == \"R\":\n",
    "                hybrid_pred = symb_pred\n",
    "            elif pred == \"BR\":\n",
    "                hybrid_pred = dl_pred\n",
    "            # If you have trained your own model, please use following code (and abbreviations):\n",
    "            #if pred == \"DL\":\n",
    "            #    hybrid_pred = dl_pred\n",
    "            #elif pred == \"S\":\n",
    "            #    hybrid_pred = symb_pred\n",
    "            #elif pred == \"B\":\n",
    "            #    hybrid_pred = dl_pred        \n",
    "            # Check how many hybrid labels are indeed the correct labels.\n",
    "            #print (hybrid_pred+ \" \"+gold)\n",
    "            outputFile.write(test_id+\"\\t\"+pred+\"\\t\"+hybrid_pred+\"\\t\"+gold+\"\\n\")\n",
    "            # !!!!!!! if you are evaluating on HANS, you need the following line to merge C and N to N !!!!!!!!\n",
    "            #hybrid_pred = hybrid_pred.replace(\"C\", \"N\")\n",
    "            if hybrid_pred == gold:\n",
    "                correct += 1\n",
    "            \n",
    "        # print (\"No of correct classifications: \"+str(correct))\n",
    "        # print (\"Percentage of correct classifications: \"+str(correct/(len(test_data))))\n",
    "        print(r, e, correct/len(test_data))\n",
    "\n",
    "        # dlFile_TEST.close()\n",
    "        # symbLines_TEST.close()\n",
    "        outputFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset Lenght::  6213\nDataset Shape::  (6213, 11)\nDataset:: \n     ID  ComplexCtxs  ContraFlag  Veridical  Antiveridical  Averidical  \\\n0    4a            1           0          1              1           0   \n1    4b            0           0          1              0           0   \n2   24a            0           0          1              0           0   \n3  105a            0           0          1              0           0   \n4  116a            1           0          1              0           0   \n\n   Equals  Superclass  Subclass  Disjoint TargetLabel  \n0       1           0         0         0           B  \n1       1           0         0         0           B  \n2       1           1         0         0           B  \n3       1           1         0         0           B  \n4       0           1         0         0           B  \n"
     ]
    }
   ],
   "source": [
    "# Read training set that was created in the previous section.\n",
    "training_data = pd.read_csv('/home/adam/anu/comp4450/hy-nli/Hy-NLI/data/SICK/trial_and_train/SICK_trial_and_train_BERT_GKR4NLI_input_for_hybrid_classifier.csv', sep='\\t',header=0)\n",
    "    \n",
    "print (\"Dataset Lenght:: \", len(training_data))\n",
    "print (\"Dataset Shape:: \", training_data.shape)\n",
    "\n",
    "print (\"Dataset:: \")\n",
    "print (training_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "B     4706\n",
       "DL    1234\n",
       "N      195\n",
       "S       78\n",
       "Name: TargetLabel, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "# Check how the labels are distributed in order to resample properly.\n",
    "dl = training_data[training_data.TargetLabel==\"DL\"]\n",
    "symbolic = training_data[training_data.TargetLabel==\"S\"]\n",
    "both = training_data[training_data.TargetLabel==\"B\"]\n",
    "none = training_data[training_data.TargetLabel==\"N\"]\n",
    "training_data['TargetLabel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "S     78\n",
       "DL    55\n",
       "B     55\n",
       "Name: TargetLabel, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "# the pairs with DL and B target labels have to be downsampled to match the much fewer instances of S labels\n",
    "# (SICK is a relatively easy corpus where most pairs can be solved equally well by the two approaches and the\n",
    "# rest of them can be mostly solved by the DL model.)\n",
    "dl_downsampled = resample(dl, \n",
    "                                replace=False,     # sample with replacement\n",
    "                               n_samples=55,    # to match minority class 60\n",
    "                             random_state=123) # reproducible results\n",
    "\n",
    "both_downsampled = resample(both, \n",
    "                                replace=True,     # sample with replacement\n",
    "                               n_samples=55,    # to match minority class 78\n",
    "                             random_state=123) # reproducible results\n",
    "\n",
    "\n",
    "resampled_set = pd.concat([symbolic,dl_downsampled, both_downsampled])\n",
    "resampled_set['TargetLabel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training set\n",
    "X_train = resampled_set.values[:, 1:-1]\n",
    "Y_train = resampled_set.values[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train a random forest for XplaiNLI\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# clf_forest = RandomForestClassifier(n_estimators=30, max_depth=25, random_state=0)\n",
    "# clf_forest.fit(X_train, Y_train)\n",
    "# import pickle\n",
    "# filename = 'hybrid_model_for_XplaiNLI.sav'\n",
    "# pickle.dump(clf_forest, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.01, hidden_layer_sizes=(8,), learning_rate='adaptive',\n",
       "              learning_rate_init=0.01, max_iter=1000)"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(8,),\n",
    "                                       activation='relu',\n",
    "                                       solver='adam',\n",
    "                                       learning_rate='adaptive',\n",
    "                                       max_iter=1000,\n",
    "                                       learning_rate_init=0.01,\n",
    "                                       alpha=0.01)\n",
    "mlp.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 0 0.20156959933911606\n",
      "0 1 0.19991738950846757\n",
      "0 2 0.19578686493184635\n",
      "0 3 0.19991738950846757\n",
      "0 4 0.2040479140850888\n",
      "20 0 0.20012391573729862\n",
      "20 1 0.20342833539859562\n",
      "20 2 0.201363073110285\n",
      "20 3 0.20177612556794713\n",
      "20 4 0.201363073110285\n",
      "40 0 0.20156959933911606\n",
      "40 1 0.20177612556794713\n",
      "40 2 0.19950433705080545\n",
      "40 3 0.20177612556794713\n",
      "40 4 0.20074349442379183\n",
      "60 0 0.20115654688145396\n",
      "60 1 0.20260223048327136\n",
      "60 2 0.20095002065262288\n",
      "60 3 0.1992978108219744\n",
      "60 4 0.19971086327963652\n",
      "80 0 0.2023957042544403\n",
      "80 1 0.20177612556794713\n",
      "80 2 0.20322180916976457\n",
      "80 3 0.20198265179677818\n",
      "80 4 0.20012391573729862\n",
      "100 0 0.20074349442379183\n",
      "100 1 0.19950433705080545\n",
      "100 2 0.2003304419661297\n",
      "100 3 0.20053696819496075\n",
      "100 4 0.20177612556794713\n"
     ]
    }
   ],
   "source": [
    "bert_path_base = '/home/adam/anu/comp4450/hy-nli/Hy-NLI/output/bert/results/untransform/results-untransform-rho'\n",
    "gkr_path = '/home/adam/anu/comp4450/hy-nli/Hy-NLI/gkr4nli/data/untransformed/sick_test_untransform-results.csv' \n",
    "merged_file_base = '/home/adam/anu/comp4450/hy-nli/Hy-NLI/output/hybrid-retrained/sick_input/untransform-rho'\n",
    "output_path_base = '/home/adam/anu/comp4450/hy-nli/Hy-NLI/output/hybrid-retrained/untransform/results-hy-nli-untransform-rho'\n",
    "\n",
    "for rho in range(0,120,20):\n",
    "    r = str(rho)\n",
    "    for experiment in range(5):\n",
    "        e = str(experiment)\n",
    "        end = r + '-' + e + '.csv'\n",
    "        bert_path = bert_path_base + end\n",
    "        merged_file = merged_file_base + end\n",
    "        output_path = output_path_base + end\n",
    "\n",
    "        \n",
    "        # first\n",
    "        dlFile = open (bert_path, 'r')\n",
    "        symbFile = open (gkr_path, 'r')\n",
    "        mergedFile = open (merged_file, 'w')\n",
    "        mergedFile.write(\"ID\\tComplexCtxs\\tContraFlag\\tVeridical\\tAntiveridical\\tAveridical\\tEquals\\tSuperclass\\tSubclass\\tDisjoint\\tTargetLabel\\n\")\n",
    "\n",
    "        # second\n",
    "        # Read the files and initialize parameters\n",
    "        dlLines = dlFile.readlines()\n",
    "        symbLines = symbFile.readlines()\n",
    "        # Create a dictionary holding the predicted label of the DL model. Will need it for evaluation as well.\n",
    "        dict_of_dl_labels = defaultdict()\n",
    "\n",
    "        # third\n",
    "        for line in dlLines:\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            elements = line.split(\"\\t\")\n",
    "            dict_of_dl_labels[elements[0]] = elements[1].replace(\"0\", \"E\").replace(\"1\", \"C\").replace(\"2\", \"N\")\n",
    "\n",
    "\n",
    "        # fourth\n",
    "        for line in symbLines:\n",
    "            if line.startswith(\"pair_ID\"):\n",
    "                continue\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            elements = line.split(\"\\t\")\n",
    "            elements = elements[0:-1]\n",
    "            id_ = elements[0]\n",
    "            gold_label = elements[1]\n",
    "            features = elements[2:-1]\n",
    "            symb_label = elements[-1]\n",
    "            dl_label = dict_of_dl_labels[id_]\n",
    "            target_label = \"\"\n",
    "            if dl_label == gold_label and symb_label == gold_label:\n",
    "                target_label = \"B\"\n",
    "            elif dl_label == gold_label:\n",
    "                target_label = \"DL\"\n",
    "            elif symb_label == gold_label:\n",
    "                target_label = \"S\"\n",
    "            else:\n",
    "                target_label = \"N\"\n",
    "            mergedFile.write(id_+\"\\t\"+\"\\t\".join([str(f) for f in features])+\"\\t\" + target_label+\"\\n\")\n",
    "\n",
    "\n",
    "        # Close all opened files.\n",
    "        dlFile.close()\n",
    "        symbFile.close()\n",
    "        mergedFile.close()\n",
    "\n",
    "\n",
    "\n",
    "        # evaluate\n",
    "        dlFile_TEST = open(bert_path, \"r\")\n",
    "        symbFile_TEST = open(gkr_path, \"r\")\n",
    "\n",
    "        # Read the files\n",
    "        dlLines_TEST = dlFile_TEST.readlines()\n",
    "        symbLines_TEST = symbFile_TEST.readlines()\n",
    "\n",
    "        # Create a dictionary holding the predicted label of the DL model.\n",
    "        dict_of_dl_labels_TEST = defaultdict()\n",
    "        # Create a dictionary holding the predicted label of the GKR4NLI.\n",
    "        dict_of_symb_labels_TEST = defaultdict()\n",
    "        # Create a dictionary holding the gold label.\n",
    "        dict_of_gold_labels_TEST = defaultdict()\n",
    "\n",
    "\n",
    "        # Go through the dl file and store the predicted label of each pair in a dictionary.\n",
    "        for line in dlLines_TEST:\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            elements = line.split(\"\\t\")\n",
    "            dict_of_dl_labels_TEST[elements[0]] = elements[1].replace(\"0\", \"E\").replace(\"1\", \"C\").replace(\"2\", \"N\")\n",
    "\n",
    "            \n",
    "        # Go through the symbolic file and store the predicted label of GKR4NLI and the gold labels of each pair in a dictionary.\n",
    "        for line in symbLines_TEST:\n",
    "            if line.startswith(\"pair_ID\"):\n",
    "                continue\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            elements = line.split(\"\\t\")\n",
    "            id_ = elements[0]\n",
    "            gold_label = elements[1]\n",
    "            dict_of_gold_labels_TEST[id_] = gold_label\n",
    "            symb_label = elements[-1]\n",
    "            dict_of_symb_labels_TEST[id_] = symb_label\n",
    "\n",
    "\n",
    "        # six\n",
    "        # Read test set to evaluate on it.\n",
    "        test_data = pd.read_csv(merged_file, sep='\\t', header=0)\n",
    "\n",
    "        # print (\"Dataset Lenght:: \", len(test_data))\n",
    "        # print (\"Dataset Shape:: \", test_data.shape)\n",
    "\n",
    "        # print (\"Dataset:: \")\n",
    "        # print (test_data.head())\n",
    "\n",
    "\n",
    "        X_test = test_data.values[:, 1:-1]\n",
    "        Y_test = test_data.values[:, -1]\n",
    "\n",
    "\n",
    "        # seven\n",
    "        # Predict labels for test set. The predicted labels are one of S, DL or B, expressing the component that the hybrid \n",
    "        # classifier predicted to get the inference relation right.\n",
    "        predicted = mlp.predict(X_test)\n",
    "        # Write the final results into a file for better error-analysis.\n",
    "        outputFile = open(output_path, 'w')\n",
    "        outputFile.write(\"pair_ID\\tHybridLabel\\tMappedLabel\\tGoldLabel\\n\")\n",
    "\n",
    "        i = 0\n",
    "        correct = 0\n",
    "        for pred in predicted:\n",
    "            test_id = np.array2string(test_data.values[i:i+1,0])\n",
    "            test_id = test_id.replace(\"'\",\"\").replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "            #print (test_id)\n",
    "            i += 1\n",
    "            dl_pred = dict_of_dl_labels_TEST[test_id]\n",
    "            symb_pred = dict_of_symb_labels_TEST[test_id]\n",
    "            gold = dict_of_gold_labels_TEST[test_id]\n",
    "            hybrid_pred = \"\"   \n",
    "            # map hybrid prediction to a proper inference label\n",
    "            # if you are using our trained classifier, you have to use the following code: (because we used slighlty different\n",
    "            # abbreviations for each label -- B for BERT, R for rule-based and BR for bert/rule-based) \n",
    "            if pred == \"B\":\n",
    "                hybrid_pred = dl_pred\n",
    "            elif pred == \"R\":\n",
    "                hybrid_pred = symb_pred\n",
    "            elif pred == \"BR\":\n",
    "                hybrid_pred = dl_pred\n",
    "            # If you have trained your own model, please use following code (and abbreviations):\n",
    "            #if pred == \"DL\":\n",
    "            #    hybrid_pred = dl_pred\n",
    "            #elif pred == \"S\":\n",
    "            #    hybrid_pred = symb_pred\n",
    "            #elif pred == \"B\":\n",
    "            #    hybrid_pred = dl_pred        \n",
    "            # Check how many hybrid labels are indeed the correct labels.\n",
    "            #print (hybrid_pred+ \" \"+gold)\n",
    "            outputFile.write(test_id+\"\\t\"+pred+\"\\t\"+hybrid_pred+\"\\t\"+gold+\"\\n\")\n",
    "            # !!!!!!! if you are evaluating on HANS, you need the following line to merge C and N to N !!!!!!!!\n",
    "            #hybrid_pred = hybrid_pred.replace(\"C\", \"N\")\n",
    "            if hybrid_pred == gold:\n",
    "                correct += 1\n",
    "            \n",
    "        # print (\"No of correct classifications: \"+str(correct))\n",
    "        # print (\"Percentage of correct classifications: \"+str(correct/(len(test_data))))\n",
    "        print(r, e, correct/len(test_data))\n",
    "\n",
    "        # dlFile_TEST.close()\n",
    "        # symbLines_TEST.close()\n",
    "        outputFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Open input and output files. The input files are the output files of the GKR4NLI system and the DL model.\n",
    "dlFile = open ('/home/adam/anu/comp4450/hy-nli/Hy-NLI/data/SICK/test/SICK_test_BERT_results.csv', 'r')\n",
    "symbFile = open ('/home/adam/anu/comp4450/hy-nli/Hy-NLI/data/SICK/test/SICK_test_GKR4NLI_results.csv', 'r')\n",
    "mergedFile = open ('/home/adam/anu/comp4450/hy-nli/Hy-NLI/output/hybrid/untransform/SICK_test_BERT_GKR4NLI_input_for_hybrid_classifier.csv', 'w')\n",
    "mergedFile.write(\"ID\\tComplexCtxs\\tContraFlag\\tVeridical\\tAntiveridical\\tAveridical\\tEquals\\tSuperclass\\tSubclass\\tDisjoint\\tTargetLabel\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the files and initialize parameters\n",
    "dlLines = dlFile.readlines()\n",
    "symbLines = symbFile.readlines()\n",
    "# Create a dictionary holding the predicted label of the DL model. Will need it for evaluation as well.\n",
    "dict_of_dl_labels = defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through the dl file and store the predicted label of each pair in a dictionary.\n",
    "for line in dlLines:\n",
    "    line = line.replace(\"\\n\", \"\")\n",
    "    elements = line.split(\"\\t\")\n",
    "    dict_of_dl_labels[elements[0]] = elements[1].replace(\"0\", \"E\").replace(\"1\", \"C\").replace(\"2\", \"N\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through the symbolic file and compare the symbolic and the dl labels to gold and produce the final\n",
    "# target label that will be learned by the classifier. Produce a merged file with the features and the target label.\n",
    "for line in symbLines:\n",
    "    if line.startswith(\"pair_ID\"):\n",
    "        continue\n",
    "    line = line.replace(\"\\n\", \"\")\n",
    "    elements = line.split(\"\\t\")\n",
    "    id_ = elements[0]\n",
    "    gold_label = elements[1]\n",
    "    features = elements[2:-1]\n",
    "    symb_label = elements[-1]\n",
    "    dl_label = dict_of_dl_labels[id_]\n",
    "    target_label = \"\"\n",
    "    if dl_label == gold_label and symb_label == gold_label:\n",
    "        target_label = \"B\"\n",
    "    elif dl_label == gold_label:\n",
    "        target_label = \"DL\"\n",
    "    elif symb_label == gold_label:\n",
    "        target_label = \"S\"\n",
    "    else:\n",
    "         target_label = \"N\"\n",
    "    mergedFile.write(id_+\"\\t\"+\"\\t\".join([str(f) for f in features])+\"\\t\" + target_label+\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close all opened files.\n",
    "dlFile.close()\n",
    "symbFile.close()\n",
    "mergedFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, read the test set to store the symbolic, DL and gold labels of the pairs\n",
    "\n",
    "# Open the files\n",
    "dlFile_TEST = open('/home/adam/anu/comp4450/hy-nli/Hy-NLI/data/SICK/test/SICK_test_BERT_results.csv', \"r\")\n",
    "symbFile_TEST = open('/home/adam/anu/comp4450/hy-nli/Hy-NLI/data/SICK/test/SICK_test_GKR4NLI_results.csv', \"r\")\n",
    "\n",
    "# Read the files\n",
    "dlLines_TEST = dlFile_TEST.readlines()\n",
    "symbLines_TEST = symbFile_TEST.readlines()\n",
    "\n",
    "# Create a dictionary holding the predicted label of the DL model.\n",
    "dict_of_dl_labels_TEST = defaultdict()\n",
    "# Create a dictionary holding the predicted label of the GKR4NLI.\n",
    "dict_of_symb_labels_TEST = defaultdict()\n",
    "# Create a dictionary holding the gold label.\n",
    "dict_of_gold_labels_TEST = defaultdict()\n",
    "\n",
    "\n",
    "# Go through the dl file and store the predicted label of each pair in a dictionary.\n",
    "for line in dlLines_TEST:\n",
    "    line = line.replace(\"\\n\", \"\")\n",
    "    elements = line.split(\"\\t\")\n",
    "    dict_of_dl_labels_TEST[elements[0]] = elements[1].replace(\"0\", \"E\").replace(\"1\", \"C\").replace(\"2\", \"N\")\n",
    "\n",
    "    \n",
    "# Go through the symbolic file and store the predicted label of GKR4NLI and the gold labels of each pair in a dictionary.\n",
    "for line in symbLines_TEST:\n",
    "    if line.startswith(\"pair_ID\"):\n",
    "        continue\n",
    "    line = line.replace(\"\\n\", \"\")\n",
    "    elements = line.split(\"\\t\")\n",
    "    id_ = elements[0]\n",
    "    gold_label = elements[1]\n",
    "    dict_of_gold_labels_TEST[id_] = gold_label\n",
    "    symb_label = elements[-1]\n",
    "    dict_of_symb_labels_TEST[id_] = symb_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset Lenght::  4674\nDataset Shape::  (4674, 11)\nDataset:: \n    ID  ComplexCtxs  ContraFlag  Veridical  Antiveridical  Averidical  Equals  \\\n0   6a            0           0          1              0           0       0   \n1   7a            0           0          1              0           0       1   \n2   8a            0           0          1              0           0       1   \n3  10a            0           0          1              0           0       1   \n4  11a            0           0          1              0           0       1   \n\n   Superclass  Subclass  Disjoint TargetLabel  \n0           0         1         0           B  \n1           1         0         0           B  \n2           1         0         0           B  \n3           0         0         0           B  \n4           1         0         0           B  \n"
     ]
    }
   ],
   "source": [
    "# Read test set to evaluate on it.\n",
    "test_data = pd.read_csv('/home/adam/anu/comp4450/hy-nli/Hy-NLI/output/hybrid/untransform/SICK_test_BERT_GKR4NLI_input_for_hybrid_classifier.csv', sep= '\\t', header= 0)\n",
    "\n",
    "print (\"Dataset Lenght:: \", len(test_data))\n",
    "print (\"Dataset Shape:: \", test_data.shape)\n",
    "\n",
    "print (\"Dataset:: \")\n",
    "print (test_data.head())\n",
    "\n",
    "\n",
    "X_test = test_data.values[:, 1:-1]\n",
    "Y_test = test_data.values[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No of correct classifications: 3965\nPercentage of correct classifications: 0.8483097988874626\n"
     ]
    }
   ],
   "source": [
    "# Predict labels for test set. The predicted labels are one of S, DL or B, expressing the component that the hybrid \n",
    "# classifier predicted to get the inference relation right.\n",
    "predicted = mlp.predict(X_test)\n",
    "# Write the final results into a file for better error-analysis.\n",
    "outputFile = open('/home/adam/anu/comp4450/hy-nli/Hy-NLI/output/hybrid/untransform/SICK_test_hybrid_results_with_BERT.csv', 'w')\n",
    "outputFile.write(\"pair_ID\\tHybridLabel\\tMappedLabel\\tGoldLabel\\n\")\n",
    "\n",
    "i = 0\n",
    "correct = 0\n",
    "for pred in predicted:\n",
    "    test_id = np.array2string(test_data.values[i:i+1,0])\n",
    "    test_id = test_id.replace(\"'\",\"\").replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "    #print (test_id)\n",
    "    i += 1\n",
    "    dl_pred = dict_of_dl_labels_TEST[test_id]\n",
    "    symb_pred = dict_of_symb_labels_TEST[test_id]\n",
    "    gold = dict_of_gold_labels_TEST[test_id]\n",
    "    hybrid_pred = \"\"   \n",
    "    # map hybrid prediction to a proper inference label\n",
    "    # if you are using our trained classifier, you have to use the following code: (because we used slighlty different\n",
    "    # abbreviations for each label -- B for BERT, R for rule-based and BR for bert/rule-based) \n",
    "    if pred == \"B\":\n",
    "        hybrid_pred = dl_pred\n",
    "    elif pred == \"R\":\n",
    "        hybrid_pred = symb_pred\n",
    "    elif pred == \"BR\":\n",
    "        hybrid_pred = dl_pred\n",
    "    # If you have trained your own model, please use following code (and abbreviations):\n",
    "    #if pred == \"DL\":\n",
    "    #    hybrid_pred = dl_pred\n",
    "    #elif pred == \"S\":\n",
    "    #    hybrid_pred = symb_pred\n",
    "    #elif pred == \"B\":\n",
    "    #    hybrid_pred = dl_pred        \n",
    "    # Check how many hybrid labels are indeed the correct labels.\n",
    "    #print (hybrid_pred+ \" \"+gold)\n",
    "    outputFile.write(test_id+\"\\t\"+pred+\"\\t\"+hybrid_pred+\"\\t\"+gold+\"\\n\")\n",
    "    # !!!!!!! if you are evaluating on HANS, you need the following line to merge C and N to N !!!!!!!!\n",
    "    #hybrid_pred = hybrid_pred.replace(\"C\", \"N\")\n",
    "    if hybrid_pred == gold:\n",
    "        correct += 1\n",
    "\n",
    "print (\"No of correct classifications: \"+str(correct))\n",
    "print (\"Percentage of correct classifications: \"+str(correct/(len(test_data))))\n",
    "\n",
    "outputFile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3710jvsc74a57bd081cfb9c11872635c5f9cdb5043a7a6e1273bdf09f9bced445237db3159c114b6",
   "display_name": "Python 3.7.10 64-bit ('tensorflow': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}